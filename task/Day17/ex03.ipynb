{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c93bb6c",
   "metadata": {},
   "source": [
    "\n",
    "### Positional Encoding의 원리\n",
    "\n",
    "Transformer 모델은 입력 시퀀스의 순서 정보를 학습하기 위해 Positional Encoding을 사용합니다. 이는 입력 벡터에 위치 정보를 추가하여 순서 정보를 보존하는 방법입니다. Transformer는 입력 시퀀스의 순차적 특성을 고려하지 않기 때문에, 각 단어의 위치 정보를 벡터에 더해줌으로써 모델이 순서를 이해할 수 있게 합니다.\n",
    "\n",
    "Positional Encoding은 주기적인 함수를 사용하여 구현됩니다. 가장 일반적으로 사용되는 방법은 사인(sine)과 코사인(cosine) 함수를 사용하는 것입니다. 이 방법은 다음과 같은 수식으로 정의됩니다:\n",
    "\n",
    "$$\n",
    "PE_{(pos, 2i)} = \\sin\\left(\\frac{pos}{10000^{2i/d_{model}}}\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "PE_{(pos, 2i+1)} = \\cos\\left(\\frac{pos}{10000^{2i/d_{model}}}\\right)\n",
    "$$\n",
    "\n",
    "여기서 \\(pos\\)는 단어의 위치, \\(i\\)는 차원의 인덱스, \\(d_{model}\\)은 모델의 차원 수입니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1899e525",
   "metadata": {},
   "source": [
    "\n",
    "### 다른 위치 인코딩 방법들\n",
    "\n",
    "다양한 위치 인코딩 방법들이 제안되었으며, 각 방법은 위치 정보를 인코딩하는 방식이 다릅니다. 다음은 몇 가지 대표적인 방법들입니다:\n",
    "\n",
    "1. **Learned Positional Encoding**:\n",
    "   - 위치 인코딩을 학습 가능한 파라미터로 설정하여, 모델이 훈련 중에 위치 정보를 학습하게 합니다. 이는 고정된 주기적 함수 대신 데이터에 맞춰 위치 정보를 최적화할 수 있습니다.\n",
    "   \n",
    "2. **Absolute Positional Encoding**:\n",
    "   - 고정된 절대 위치 값을 사용하는 방식입니다. 각 위치에 대해 고유한 값을 할당하며, 주로 시퀀스의 처음부터 끝까지의 절대적인 위치를 나타냅니다.\n",
    "\n",
    "3. **Relative Positional Encoding**:\n",
    "   - 절대적인 위치가 아닌 상대적인 위치 정보를 인코딩합니다. 이는 특정 단어 쌍 간의 거리나 순서를 학습하는 데 유용하며, 일반적으로 더 유연하고 강력한 표현력을 가집니다.\n",
    "\n",
    "### 비교\n",
    "\n",
    "- **고정된 주기적 함수 (Sine, Cosine)**:\n",
    "  - 장점: 계산이 간단하고 주기성을 이용해 위치 정보를 효과적으로 인코딩.\n",
    "  - 단점: 데이터 특성에 맞춘 최적화가 불가능.\n",
    "  \n",
    "- **Learned Positional Encoding**:\n",
    "  - 장점: 데이터에 맞춰 최적화할 수 있어 더 나은 성능을 기대할 수 있음.\n",
    "  - 단점: 추가적인 학습 파라미터가 필요하고, 데이터에 따라 과적합(overfitting) 가능성 존재.\n",
    "  \n",
    "- **Absolute Positional Encoding**:\n",
    "  - 장점: 단순하고 직관적.\n",
    "  - 단점: 긴 시퀀스에 대해 일반화가 어려울 수 있음.\n",
    "  \n",
    "- **Relative Positional Encoding**:\n",
    "  - 장점: 단어 간의 상대적 위치를 효과적으로 학습 가능, 긴 시퀀스에서도 유연하게 작동.\n",
    "  - 단점: 구현이 복잡할 수 있고, 추가적인 계산이 필요.\n",
    "\n",
    "각 방법은 특정 응용 분야나 데이터셋에 따라 장단점이 다르게 나타날 수 있습니다. 적절한 위치 인코딩 방법을 선택하는 것은 모델의 성능에 큰 영향을 미칠 수 있습니다.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
